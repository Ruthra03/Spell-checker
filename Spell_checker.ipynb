{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWKCjnwG1mmBIJH/6PFeZ1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ruthra03/Spell-checker/blob/main/Spell_checker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amP-7WCzqvfV",
        "outputId": "03fba537-5a7f-4113-814d-3d90a408e3bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corrected Text: hello world of python\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import collections\n",
        "\n",
        "def get_words(text):\n",
        "    \"\"\"Tokenize text into words.\"\"\"\n",
        "    return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "def candidates(word):\n",
        "    \"\"\"Generate candidate words with edit distance of 1.\"\"\"\n",
        "    alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
        "    deletes = [left + right[1:] for left, right in splits if right]\n",
        "    inserts = [left + c + right for left, right in splits for c in alphabet]\n",
        "    replaces = [left + c + right[1:] for left, right in splits if right for c in alphabet]\n",
        "    transposes = [left + right[1] + right[0] + right[2:] for left, right in splits if len(right) > 1]\n",
        "    return set(deletes + inserts + replaces + transposes),deletes,splits\n",
        "\n",
        "def spell_checker(text, word_freq):\n",
        "    \"\"\"Spell check the input text.\"\"\"\n",
        "    words = get_words(text)\n",
        "    corrected_text = []\n",
        "\n",
        "    for word in words:\n",
        "        if word in word_freq:\n",
        "            corrected_text.append(word)  # Word is correct\n",
        "        else:\n",
        "            word_candidates,deletes,splits = candidates(word)\n",
        "            #print(word_candidates)\n",
        "            #print(splits)\n",
        "            #print(deletes)\n",
        "            best_candidate = max(word_candidates, key=lambda x: word_freq.get(x, 0))\n",
        "            corrected_text.append(best_candidate)\n",
        "\n",
        "    return ' '.join(corrected_text)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Sample word frequency dictionary\n",
        "    word_freq = {'hello': 100, 'world': 150, 'python': 80, 'of': 30, 'is': 20}\n",
        "\n",
        "    # Sample text to be spell checked\n",
        "    text = \"helo worlt of pyton\"\n",
        "\n",
        "    # Spell check the text\n",
        "    corrected_text = spell_checker(text, word_freq)\n",
        "    print(\"Corrected Text:\", corrected_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3yN-bF0Jq1Yz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}